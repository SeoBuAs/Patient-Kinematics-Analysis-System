# Patient-Kinematics-Analysis-System
Deep learning-based movement analysis system for patient diagnosis using biomechanical data.

## ğŸ“Œ Overview

AI-powered system that analyzes human movement patterns from biomechanical data to assist in patient diagnosis. Uses state-of-the-art deep learning models (FT-Transformer, SAINT, TabNet, TabPFN) and traditional ML algorithms with SHAP/LIME explainability.

## ğŸ—‚ï¸ Project Structure

```
rehabilitation-analysis/
â”œâ”€â”€ simple_gradio_interface.py       # Web interface (main entry point)
â”œâ”€â”€ run_complete_experiment.py       # Train all ML models
â”œâ”€â”€ run_complete_experiment_no_vif.py # Train all ML models (no VIF)
â”œâ”€â”€ run_deep_learning_experiment.py  # Train DL models only
â”œâ”€â”€ run_deep_learning_experiment_no_vif.py # Train DL models (no VIF)
â”œâ”€â”€ content/                         # Data directory (.mot files)
â”‚   â””â”€â”€ XXX_gait_*.mot              # Kinematics data files
â”œâ”€â”€ data_loader/
â”‚   â””â”€â”€ kinematics_loader.py        # Data loading & preprocessing
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ nested_cv.py                # Patient-based nested CV
â”‚   â””â”€â”€ deep_models.py              # Deep learning training
â””â”€â”€ models/
    â”œâ”€â”€ ft_transformer_wrapper.py   # FT-Transformer wrapper
    â”œâ”€â”€ saint_wrapper.py            # SAINT wrapper
    â”œâ”€â”€ tabnet_wrapper.py           # TabNet wrapper
    â””â”€â”€ tabpfn_wrapper.py           # TabPFN wrapper
```

## ğŸ“‹ How to Prepare Your Data

This system analyzes movement data from CSV or MoT files. Here's how to get your data ready:

### ğŸ“± Step 1: Record Movement (OpenCap)
- Go to **[OpenCap.ai](https://www.opencap.ai/)**
- Use your smartphone to record walking/movement videos
- Follow their simple setup guide (2 phones at 30-45Â° angles)
- Let OpenCap process your video into 3D movement data

### ğŸ”§ Step 2: Process Data (OpenSim) 
- Download **[OpenSim](https://simtk.org/frs/?group_id=91)**
- Import your OpenCap data into OpenSim
- Run "Inverse Kinematics" analysis
- Export the results as CSV or MoT files

### ğŸ“¤ Step 3: Upload & Analyze
- Place your processed files in the `content/` directory
- Or use the Gradio web interface to upload files
- Get AI-powered movement analysis and diagnosis

ğŸ’¡ **Tip**: Both OpenCap and OpenSim are free, open-source tools with detailed tutorials!

## ğŸ“Š Features

The system analyzes **30+ biomechanical features** including:

- **Pelvis**: tilt, list, rotation, translation (tx, ty, tz)
- **Hip**: flexion, adduction, rotation (left & right)
- **Knee**: angle (left & right)
- **Ankle**: angle, subtalar angle, mtp angle (left & right)
- **Lumbar**: extension, bending, rotation
- **Arm**: flexion, adduction, rotation (left & right)
- **Elbow**: flexion, pro_sup (left & right)

## ğŸ”¬ Methodology

### Patient-Based Cross-Validation
```
1. Split data by patient (not by samples)
   â†“
2. Nested CV (Outer: 5-fold, Inner: 3-fold)
   â†“
3. VIF-based feature selection (optional)
   â†“
4. Hyperparameter tuning (GridSearchCV)
   â†“
5. Train on full training set
   â†“
6. Evaluate on held-out test set
   â†“
7. SHAP & LIME explainability
```

## ğŸš€ Quick Start

### 1. Train Models

#### Train All Models (ML + DL)
```bash
# With VIF feature selection
python run_complete_experiment.py

# Without VIF
python run_complete_experiment_no_vif.py
```

#### Train Deep Learning Models Only
```bash
# With VIF feature selection
python run_deep_learning_experiment.py

# Without VIF
python run_deep_learning_experiment_no_vif.py
```

### 2. Launch Web Interface After Training

```bash
python simple_gradio_interface.py
```

Then open your browser at `http://localhost:7860`

